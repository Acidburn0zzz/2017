<!DOCTYPE html>
<html lang="en">
<head>
	<!-- $title:Ind.ie — Why? -->
	<!-- @import '../../assets/includes/_head.kit' -->
	<link rel='stylesheet' type='text/css' href='css/style.css'>
</head>
<body class='why'>
	<header class="site-header">
		<!-- @import '../../assets/includes/_nav.kit' -->
		<!-- @import '../../about/includes/_nav.kit' -->
	</header>
	<div class='main'>
		<h1>Why?</h1>

		<p>Why does Ind.ie do what we do? In 2013, Edward Snowden revealed that many citizens around the world were being spied upon by their own, and other governments. The governments had been collecting, storing, and analysing, their communications data on a massive scale with help from corporations such as Apple, AOL, Google, Facebook, Microsoft, and Yahoo. Many of these <a href='http://techcrunch.com/2013/06/06/google-facebook-apple-deny-participation-in-nsa-prism-program/'>denied their involvement</a>, and said they only complied with data requests when issued with a court order. Aral looked at this and questioned, why do these corporations need to store our data anyway? Surely blanket surveillance wouldn’t be possible if these corporations didn’t store our (unencrypted) data in the first place?</p>

		<figure>
			<img src='images/snowden.jpg' alt='Edward Snowden in the CITIZENFOUR documentary'/>
			<figcaption>Edward Snowden in <a href='https://citizenfourfilm.com'>CITIZENFOUR</a>. <small>Photo Laura Poitras/Praxis Films (CC BY-SA 3.0)</small></figcaption>
		</figure>

		<p>Our data is out of our control. We might (wisely or unwisely) choose to publicly share our statuses, personal information, media and locations, or we might choose to only share this data with our friends. But when we’re using services such as Facebook or Google, it’s just an illusion of choice—however we share, we’re exposing ourselves to a wide audience, both corporate and government. We have so much more to worry about than future employers seeing photos of us when we’ve had too much to drink.</p>

		<h2>What do they have on us?</h2>

		<p>These corporations hold a lot of information about us. They store the stuff we share on their sites and apps, and provide us with data storage for our emails, photos, videos, and much more. When we or our friends share stuff on their services, either publicly or privately, clever algorithms can derive a lot of of detailed knowledge from a small amount of information. Did you know that <a href="http://www.abc.net.au/science/articles/2014/04/15/3985934.htm">you’re pregnant</a>? Did you know that <a href="http://www.wired.com/2013/03/facebook-like-research/">you’re not considered intelligent</a>? Did you know that <a href="http://www.businessinsider.com/facebook-predicts-relationship-status-2013-10?op=1&amp;IR=T">your relationship is about to end</a>? The algorithms <a href="http://www.telegraph.co.uk/news/science/science-news/11340166/Facebook-knows-you-better-than-your-members-of-your-own-family.html">know us better than our families</a> and only need to know ten of our Facebook Likes before they <a href="http://www.pnas.org/content/112/4/1036.full">know us better than our average work colleague</a>.</p>

		<figure>
			<img src='images/facebook-graph.jpg' alt='Facebook graph'/>
			<figcaption>Graph from <a href='http://arxiv.org/pdf/1310.6753v1.pdf'>Facebook study</a> predicting the end of relationships (with accuracy)</figcaption>
		</figure>

		<p>Analytics and big data can be used in a huge variety of ways. Many sites use our data just to ensure a web page is in the language we speak. Recommendation engines are used by <a href="http://www.pcmag.com/article2/0,2817,2402739,00.asp">companies like Netflix</a> to deliver fantastic personalised experiences. Google <a href="https://www.google.com/settings/ads?hl=en&amp;sig=ACi0TCiaFqLII9TnPNKxUv7FR0ZxuEWuwtz1tjQCMxP5D_Sk0TINAQ_ciXWzRhrUecBwmt-3ZvQfOKql4May4KXO82KAzQ7xnAH6K5ETC3AnNLBF20D3k2LOCNfH4eXmryZehWVdbuGXivmkNvAigkszUrU2p3AS5M8Vnwxs9ZxhY3mntdtpQeR3rJZ85471uf-HYb-_ZldM">creates profiles of us</a> to understand what makes us tick and sell us the right products. 23andme analyses our DNA for genetic risk factors and <a href="http://www.wired.co.uk/news/archive/2015-01/13/23andme-teams-with-big-pharma">sells the data to pharmaceutical companies</a>. Ecommerce sites like Amazon know how to <a href="http://www.wired.com/2011/04/st_essay_persuasion_profiling/">appeal to you as an individual</a>, and whether you’re more persuaded by seeing friend buying product, or an expert recommending a product. Facebook can <a href="http://www.pnas.org/content/110/15/5802.full?sid=5efa0b8d-205a-49f8-ac64-70f2d15edf53">predict the likelihood that you drink alcohol or do drugs, or determine if you’re physically and mentally healthy</a>. It also <a href="http://www.telegraph.co.uk/technology/facebook/10944613/Facebook-conducted-widespread-experiments-on-user-data-to-alter-peoples-behaviour.html">experiments on us and influences our emotions</a>. What can be done with all this data varies wildly, from the incredibly convenient and useful to the downright terrifying. And when we use communication services like Gmail, we’re not just sharing our own data, but that of our friends too. Whether they want us to share it or not.</p>

		<h2>How is our data valuable?</h2>

		<p>This data has a huge value to people who may not have your best interests at heart. It can be sold at a premium to <a href='http://www.lexisnexis.com/risk/about/datasource.aspx'>data broker</a> <a href='http://www.acxiom.com/data-packages/'>companies</a> who can extract further analysis, information, and value. For both advertising purposes and other purposes. This is how <a href='https://www.thersa.org/discover/videos/event-videos/2014/04/free-is-a-lie/' title='Aral’s talk on Free Is A Lie at the RSA'>“free”</a> services make their money. This is their business model.</p>

		<p>But what if this information is sold to your boss? Your potential partner? Your insurance company? What if a future government makes something you do now illegal and wants to retroactively prosectute you?</p>

		<p>As Apple’s <a href='https://www.youtube.com/watch?v=Bmm5faI_mLo'>Tim Cook said</a>, “Some companies are not transparent that the connection of these data points produces five other things that you didn’t know that you gave up. It becomes a gigantic trove of data.” The data is so valuable that cognitive scientists are <a href="http://www.radiolab.org/story/trust-engineers/">giddy with excitement</a> at the size of studies they can conduct using Facebook. For neuroscience studies, a sample of twenty white undergraduates used to be considered sufficient to say something general about how brains work. Now Facebook works with scientists on sample sizes of hundreds of thousands to millions. The difference between more traditional scientific studies and Facebook’s studies is that Facebook’s users don’t know that they’re <a href="http://www.radiolab.org/story/trust-engineers/">probably taking part in ten “experiments” at any given time</a>. (Of course, you give your consent when you agree to the <a href='http://tacma.net'>terms and conditions</a>. But <a href="https://tosdr.org">very few people ever read the terms and conditions, or privacy policies</a>. <a href="http://www.dailymail.co.uk/news/article-2852428/Facebook-Twitter-small-print-hard-understand-say-MPs-Commons-science-committee-warns-need-law-degree-understand-terms-conditions.html">They’re not designed to be read or understood</a>.)</p>

		<h2>Why do they want our data?</h2>

		<p>The intent of the developers, their bosses, and the corporations as a whole, is key. They didn’t just decide to utilize this data because they could. They can’t afford to provide free services for nothing, and that was never their intention. It’s a <a href="http://www.theguardian.com/commentisfree/2015/mar/01/silicon-valley-promises-digital-socialism-but-is-selling-a-fairy-tale">lucrative business</a>. The <a href="https://www.schneier.com/blog/archives/2015/02/everyone_wants_.html">business model</a> of these companies is to exploit our data, to be our corporate surveillers. It’s their good fortune that we share it like—as Zuckerberg said—<a href="http://gawker.com/5636765/facebook-ceo-admits-to-calling-users-dumb-fucks">dumb fucks</a>.</p>

		<p>To say that this is a privacy issue is to give it a loaded term. The word “privacy” has been hijacked to suggest that you’re hiding things you’re ashamed about. That’s why Google’s Eric Schmidt said “if you’ve got something to hide, you shouldn’t be doing it in the first place.” But privacy is our right to choose what we do and don’t share. It’s enshrined in the <a href="http://www.un.org/en/documents/udhr/index.shtml#a12">Universal Declaration of Human Rights</a>. As <a href='https://en.wikipedia.org/wiki/Edward_snowden'>Edward Snowden</a> said:</p>

		<blockquote>
			<p>“When you say I don’t care about the right to privacy because I have nothing to hide, that is no different than saying I don’t care about freedom of speech because I have nothing to say or freedom of the press because I have nothing to write.”</p>
		</blockquote>

		<h2>What can we do about it?</h2>

		<p>So when we’re deciding which cool new tools and services to use, how are we supposed to make the right decision? We just don’t know enough about what the companies are doing with our data to judge whether it’s a worthwhile risk. What we do know is horrifying enough. And whatever corporations are doing with our data now, who knows how they’re going to use it in the future, when processing power is cheaper and faster, and they’ve amassed even more data on the pattterns of human behaviour.</p>

		<p>We need tools and services that enable us to own our own data, and give us the option to share it however we like, without conditions attached. We need true alternatives to the current business models. That’s what we at Ind.ie are creating. And that’s why we give talks, and write articles, and take part in interviews and panels; we encourage others to create alternatives too.</p>
		
		<!-- @import '../../assets/includes/_footer-call-to-action.kit' -->
		<!-- @import '../../assets/includes/_footer.kit' -->
	</div>
</body>
</html>